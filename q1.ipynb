{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import RidgeCV, LinearRegression, LassoCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [],
   "source": [
    "target = df[\"D\"].shift(-1)\n",
    "target = target.dropna()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [],
   "source": [
    "df = df[:-1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 A\n",
      "226 B\n",
      "226 C\n",
      "226 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Skwix\\AppData\\Local\\Temp/ipykernel_4004/873558226.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{columns}_Lag_{i}\"] = df[columns].shift(-i, fill_value=fill_value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D\n"
     ]
    }
   ],
   "source": [
    "for index, columns in enumerate([\"A\", \"B\", \"C\", \"D\"]):\n",
    "    print(i, columns)\n",
    "    for i in range(len(df)):\n",
    "        fill_value = df[columns].iloc[i]\n",
    "        df[f\"{columns}_Lag_{i}\"] = df[columns].shift(-i, fill_value=fill_value)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [],
   "source": [
    "df.drop([\"A\",\"B\",\"C\",\"D\"],axis=1,inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.isnull().sum().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [
    {
     "data": {
      "text/plain": "0      0.7\n1      0.9\n2      1.1\n3      0.9\n4      0.9\n      ... \n222    1.5\n223    1.6\n224    1.4\n225    1.5\n226    1.3\nName: D, Length: 227, dtype: float64"
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df,target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Standard Linear Regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [
    {
     "data": {
      "text/plain": "LinearRegression()"
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [
    {
     "data": {
      "text/plain": "     A_Lag_0  A_Lag_1  A_Lag_2  A_Lag_3  A_Lag_4  A_Lag_5  A_Lag_6  A_Lag_7  \\\n117     7.85     8.09     8.36     8.75     9.06     9.36     9.52     9.62   \n\n     A_Lag_8  A_Lag_9  ...  D_Lag_217  D_Lag_218  D_Lag_219  D_Lag_220  \\\n117     9.74     9.86  ...        2.0        1.5        1.9        1.4   \n\n     D_Lag_221  D_Lag_222  D_Lag_223  D_Lag_224  D_Lag_225  D_Lag_226  \n117        1.3        1.3        1.5        1.6        1.4        1.5  \n\n[1 rows x 908 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>A_Lag_0</th>\n      <th>A_Lag_1</th>\n      <th>A_Lag_2</th>\n      <th>A_Lag_3</th>\n      <th>A_Lag_4</th>\n      <th>A_Lag_5</th>\n      <th>A_Lag_6</th>\n      <th>A_Lag_7</th>\n      <th>A_Lag_8</th>\n      <th>A_Lag_9</th>\n      <th>...</th>\n      <th>D_Lag_217</th>\n      <th>D_Lag_218</th>\n      <th>D_Lag_219</th>\n      <th>D_Lag_220</th>\n      <th>D_Lag_221</th>\n      <th>D_Lag_222</th>\n      <th>D_Lag_223</th>\n      <th>D_Lag_224</th>\n      <th>D_Lag_225</th>\n      <th>D_Lag_226</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>117</th>\n      <td>7.85</td>\n      <td>8.09</td>\n      <td>8.36</td>\n      <td>8.75</td>\n      <td>9.06</td>\n      <td>9.36</td>\n      <td>9.52</td>\n      <td>9.62</td>\n      <td>9.74</td>\n      <td>9.86</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>1.5</td>\n      <td>1.9</td>\n      <td>1.4</td>\n      <td>1.3</td>\n      <td>1.3</td>\n      <td>1.5</td>\n      <td>1.6</td>\n      <td>1.4</td>\n      <td>1.5</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows Ã— 908 columns</p>\n</div>"
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.head(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 2.35481677,  1.39286735,  2.67660816,  2.31107878,  1.63086166,\n        2.59132257,  0.35787694,  1.49498141,  2.30464589,  0.2854191 ,\n        0.85704721,  2.49556378,  2.3179988 ,  2.30018993,  1.05099502,\n        3.55596256,  0.82983638,  0.27831789,  2.32005582,  2.23478985,\n        2.06929428,  1.23142135,  2.15222245,  2.38169825,  2.27620676,\n        1.45942335,  0.44531425, -0.13877928,  0.92474743,  0.77455911,\n        3.36489825,  1.79331587,  2.17668038,  2.81144793,  2.71341244,\n        2.08831773,  1.96102033,  0.03913256,  2.29748436,  1.11987385,\n        1.87608212,  1.86258745,  3.407668  ,  2.29080788,  2.40116598,\n        1.29839549,  1.78708739,  3.32967145,  1.36178438,  2.32186202,\n        2.22102734,  1.90310746,  1.90094926,  1.90306067,  2.74328889,\n        2.73179562,  2.04353172])"
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9662815771088938"
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, model.predict(x_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Regularisation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with this many datapoints:  150\n",
      "Using regression of type:  linear regression\n",
      "Parameter for A is -0.014456340492597261\n",
      "Parameter for B is -0.022742167710996644\n",
      "Parameter for C is -0.005885970674734085\n",
      "Parameter for D is -0.03841114559302499\n",
      "Error on held out set is:  0.9662815771088938\n",
      "\n",
      "\n",
      "\n",
      "Using regression of type:  Ridge regression using CV\n",
      "Trying these complexity parameter values (i.e.alphas):  [1.e-06 1.e-05 1.e-04 1.e-03 1.e-02 1.e-01 1.e+00 1.e+01 1.e+02 1.e+03\n",
      " 1.e+04 1.e+05 1.e+06]\n",
      "Using cross-validation got this value for the complexity parameter:  1e-06\n",
      "Parameter for A is -0.014335557329071186\n",
      "Parameter for B is -0.02298488817181485\n",
      "Parameter for C is -0.006088181675453941\n",
      "Parameter for D is -0.03847021748954685\n",
      "Error on held out set is:  0.966249990010038\n",
      "\n",
      "\n",
      "\n",
      "Using regression of type:  Lasso regression using CV\n",
      "Trying these complexity parameter values (i.e.alphas):  [1.e-06 1.e-05 1.e-04 1.e-03 1.e-02 1.e-01 1.e+00 1.e+01 1.e+02 1.e+03\n",
      " 1.e+04 1.e+05 1.e+06]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Skwix\\anaconda3\\envs\\int\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.855e-02, tolerance: 1.566e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cross-validation got this value for the complexity parameter:  1e-05\n",
      "Parameter for A is -0.4405188487261763\n",
      "Parameter for B is -0.003164872781015995\n",
      "Parameter for C is 0.0005010401786213362\n",
      "Parameter for D is -0.021371940752024716\n",
      "Error on held out set is:  0.963831337542275\n",
      "\n",
      "\n",
      "\n",
      "Training with this many datapoints:  10\n",
      "Using regression of type:  linear regression\n",
      "Parameter for A is -0.014456340492597261\n",
      "Parameter for B is -0.022742167710996644\n",
      "Parameter for C is -0.005885970674734085\n",
      "Parameter for D is -0.03841114559302499\n",
      "Error on held out set is:  0.9662815771088938\n",
      "\n",
      "\n",
      "\n",
      "Using regression of type:  Ridge regression using CV\n",
      "Trying these complexity parameter values (i.e.alphas):  [1.e-06 1.e-05 1.e-04 1.e-03 1.e-02 1.e-01 1.e+00 1.e+01 1.e+02 1.e+03\n",
      " 1.e+04 1.e+05 1.e+06]\n",
      "Using cross-validation got this value for the complexity parameter:  1e-06\n",
      "Parameter for A is -0.014335557329071186\n",
      "Parameter for B is -0.02298488817181485\n",
      "Parameter for C is -0.006088181675453941\n",
      "Parameter for D is -0.03847021748954685\n",
      "Error on held out set is:  0.966249990010038\n",
      "\n",
      "\n",
      "\n",
      "Using regression of type:  Lasso regression using CV\n",
      "Trying these complexity parameter values (i.e.alphas):  [1.e-06 1.e-05 1.e-04 1.e-03 1.e-02 1.e-01 1.e+00 1.e+01 1.e+02 1.e+03\n",
      " 1.e+04 1.e+05 1.e+06]\n",
      "Using cross-validation got this value for the complexity parameter:  1e-05\n",
      "Parameter for A is -0.4405188487261763\n",
      "Parameter for B is -0.003164872781015995\n",
      "Parameter for C is 0.0005010401786213362\n",
      "Parameter for D is -0.021371940752024716\n",
      "Error on held out set is:  0.963831337542275\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Skwix\\anaconda3\\envs\\int\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.855e-02, tolerance: 1.566e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "myalphas = np.logspace(-6, 6, 13)\n",
    "train_sizes = 150, 10\n",
    "\n",
    "models = LinearRegression, RidgeCV, LassoCV\n",
    "model_names = 'linear regression', 'Ridge regression using CV', 'Lasso regression using CV'\n",
    "\n",
    "for train_size in train_sizes:\n",
    "    print('Training with this many datapoints: ', train_size)\n",
    "    for i, model in enumerate(models):\n",
    "        print('Using regression of type: ', model_names[i])\n",
    "        if model == LinearRegression:\n",
    "            reg = model()\n",
    "        else:\n",
    "            print('Trying these complexity parameter values (i.e.alphas): ', myalphas)\n",
    "            reg = model(alphas=myalphas)\n",
    "        reg.fit(x_train,y_train)\n",
    "\n",
    "        if model != LinearRegression:\n",
    "            print('Using cross-validation got this value for the complexity parameter: ', reg.alpha_)\n",
    "        for i, name in enumerate([\"A\",\"B\",\"C\",\"D\"]):\n",
    "            print('Parameter for {0} is {1}'.format(name,reg.coef_[i]))\n",
    "\n",
    "        print('Error on held out set is: ', reg.score(x_test,y_test))\n",
    "        print('\\n\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}